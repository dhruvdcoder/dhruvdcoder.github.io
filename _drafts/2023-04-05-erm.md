---
title: Empirical Risk Minimization
layout: post
date: 2023-04-05
description: "Rigorous formulation of empirical risk"
categories: [Machinelearning, mathematics, notes]
keywords: "Machine Learning, mathematics"
tags: [Machine Learning, mathematics]
img: /relative_entropy/binary_channel.jpg
include_toc: true
redirect_to: https://notes.dhruveshp.com/Empirical+Risk+Minimization
---

We start by stating the rigorous probabilistic formulation of supervised learning that is widely accepted.


- **Def (Random Sample)**:  Assume that there is a probability space \\((\Omega, F, P)\\) and a measure space $(\mathcal X, \mathcal G)$. Then a *sample* is a collection $X^n =(X_1, \dots, X_n)$ of measurable functions $X_n:\Omega\to \mathcal X$ such that for $\omega \in \Omega$, $X^n(\omega)=(X_1(\omega), \dots,X_n(\omega))$, where $X_i$ are all *different* random variables. In other words, without anything else specified, a random sample is just a collection of measurable functions between two measure space.

- **Def (Independently distributed Sample)**: When the random variables $X_i$ in the sample $X^n$ are [[Independence of random variables\|independent]].

- **Def (IID Sample)**: When the random variables $X_i$ in the sample $X^n$ are [[Independence of random variables\|independent]] and identically distributed.

Let $(X\times Y, \Sigma_{X\times Y})$ be a measure space and let $XY: \Omega \to \mathcal X\times \mathcal Y$ be a random variable. Let $D=\{X_1 Y_1, \dots X_N Y_N\}$ be an iid sample. The ERM framework is specifically designed for supervised learning (as far as I know). Assume that we have a set of functions $\mathcal H$ where each $h\in \mathcal H$ is a (measurable?) function from $\mathcal X \to \mathcal Y$.

- **Def (Loss function in ERM)**: $l: \mathcal Y\times \mathcal Y\to \mathbb R$ that satisfies certain conditions (properness, then?)

- **Def (Expected risk or expected loss or population risk)**: Given a loss function and true distribution $P$ for $(X,Y)$, the expected loss for a function $h:\mathcal X \to \mathcal Y$ is defined as $L(h)=\mathbb E_{(x,y)\sim P}~l(h(x), y)$. Note, however, that the one cannot compute the expected loss because it involves taking expectation over true $P$. The expected loss is also denoted as $\mathcal R(h)$.

- **Def (Excess risk)**: Given a hypothesis class $\mathcal H$, and a function $g: \mathcal X\to \mathcal Y$ , the excess risk of $g$ w.r.t. $\mathcal H$ is defined as $E(g) = L(g) - \inf_{h\in \mathcal H} L(h)$. Note that we also denote $\inf\limits_{h\in \mathcal H} L(h)$ as $L(h_{\mathcal H})$.

- **Def (Empirical risk)**: When the expectation in expected loss is replaced with its MC approximation, we get the *empirical risk*. The MC approximation is done using the data as (we might drop the hat on L because it is redundant when there is N in the subscript) $$\hat L_N(h) = \frac{1}{N}\sum_{n=1}^N l(h(x_n), y_n).$$
  Notice that since $x_n, y_n\stackrel{iid}{\sim} P$ , $l_n(h)=l(h(x_n), y_n)$ are also iid RVs.
  So the expected value of the empirical risk is the same as the risk/expected loss $$\mathbb E_P \hat L(h) = \frac{1}{N}\sum_{n=1}^N L(h)=L(h)$$
  However, that does not tell much about the complete behavior of $\hat L_N(h)$. Till this point we have only talked about estimating the risk for a hypothesis using a finite data sample. We have not talked about finding a good hypothesisâ€”that will be our *learning algorithm*. But before we go looking for a good learning algorithm, can we comment on the [[Learnability of a hypothesis class]]?

## Minimizer of empirical risk

Let $\hat h$ (or $\hat f$, resp.) denote the minimizer (if it exists) $\mathop{\arg\min}\limits_{h\in\mathcal H}\hat L_n(h)$ $~~\left(\mathop{\arg\min}\limits_{f\in\mathcal F}\hat L_N(h), \text{resp.}\right)$.
In typical learning problem we would like to say that $L(\hat h)$ is very close to $L(h^*)$, where $h^*=\mathop{\arg\min}\limits_{h}L(h)$, i.e., $h^*$ is the theoretical minimizer function without restriction on the class of functions.

- A note on abuse of notation for $L(\hat h)$.
  **$L(\hat h)$ is a number but if we hold out the expectation w.r.t dataset it becomes a RV**: Notice that
  $$\begin{align}
  L(\hat h)&=\mathbb{E}_{(X,Y),(X_n, Y_n)\sim P}~~l\left(\left(\mathop{\arg\min}_{h\in\mathcal H}\,\frac{1}{N}\sum_{n=1}^N\,l(h(X_n), Y_n)\right)(X)\,, ~~Y\right)\\
  &=\mathbb{E}_{(X_n, Y_n)\sim P} ~\mathbb{E}_{(X,Y)\sim P}\left[~~ l\left(\left(\mathop{\arg\min}_{h\in\mathcal H}\,\frac{1}{N}\sum_{n=1}^N\,l(h(X_n), Y_n)\right)(X)\,, ~~Y\right)~\mid~ (X_n, Y_n) \right]\\
  \implies L(\hat h)&=\mathbb{E}_{(X_n, Y_n)\sim P} ~L_{D_N}(\hat h)
  \end{align}
  $$
  With abuse of notation, sometimes when we say $L(\hat h)$ is a RV, we really mean to use $L_{D_N}(\hat h)$.
  We want to make statements like $L_{D_N}(\hat h)$ is small in expectation or in probability. ^6c975c
