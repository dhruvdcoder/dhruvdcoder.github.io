<!DOCTYPE html>
<html lang="">

  <!-- Head -->
  <head>
        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Dhruvesh Patel | publications</title>
    <meta name="author" content="Dhruvesh Patel" />
    <meta name="description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar." />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="Dhruvesh Patel" />
    <meta property="og:type" content="website"/>
    <meta property="og:title" content="Dhruvesh Patel | publications" />
    <meta property="og:url" content="https://dhruveshp.com/publications/" />
    <meta property="og:description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar." />
    <meta property="og:image" content="https://dhruveshp.com/assets/img/blog_logo.png" />
    <meta property="og:locale" content="" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="publications" />
    <meta name="twitter:description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar." />
    <meta name="twitter:image" content="https://dhruveshp.com/assets/img/blog_logo.png" />
    <meta name="twitter:site" content="@_dhruveshp" />
    <meta name="twitter:creator" content="@_dhruveshp" />

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
	  "name": "Dhruvesh Patel",
	  "image": {
	    "@type": "ImageObject",
	    "url": "/assets/img/dp.jpg",
	    "width": 1000,
	    "height": 1000
	  },
          "sameAs": ["https://scholar.google.com/citations?user=6F2CvwoAAAAJ", "https://github.com/dhruvdcoder", "https://twitter.com/_dhruveshp"],
	  "url": "https://dhruveshp.com"
        },
	"publisher": {
          "@type": "Organization",
	  "name": "Dhruvesh Patel",
	  "url": "https://dhruveshp.com",
	  "logo": "https://dhruveshp.com/assets/img/blog_logo.png"
        },
        "url": "https://dhruveshp.com/publications/",
        "@type": "Website",
        "description": "Publications by categories in reversed chronological order. For the most up-to-date list check google scholar.",
        "headline": "publications",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    
    <link rel="icon" type="image/png" href="/assets/img/icon.png"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://dhruveshp.com/publications/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://dhruveshp.com/"><span class="font-weight-bold">Dhruvesh</span>   Patel</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/_pages/notes/">notes</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/timeline/">timeline</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">Publications by categories in reversed chronological order. For the most up-to-date list check google scholar.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">



  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="dasgupta2021word2box" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Word2Box: Capturing Set-Theoretic Semantics of Words using BoxEmbeddings</div>
          <!-- Author -->
          <div class="author">
<a href="https://ssdasgupta.github.io" target="_blank" rel="noopener noreferrer">Shib Sankar Dasgupta</a>, <a href="https://people.cs.umass.edu/~mboratko" target="_blank" rel="noopener noreferrer">Michael Boratko</a>, Siddhartha Mishra, Shriya Atmakuri, 
                  <em>Dhruvesh  Patel</em>, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Li</a>, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (To Appear)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, a prerequisite for nearly all modern machine-learning techniques. Often the objective is to capture distributional similarity via vector dot product, however this is just one relation between word meanings we may wish to capture.  It is natural to consider words as (soft) equivalence classes based on similarity, it is natural to expect the ability to perform set-theoretic operations (intersection, union, difference) on these representations. This is particularly relevant for words which are homographs- for example, “tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should  be  similar  to  “dialect”. Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations. In this work, we provide a fuzzy-set interpretation of box embeddings, and train box embeddings with a CBOW objective where contexts are represented using intersection. We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="patel2022modeling" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Modeling Label Space Interactions in Multi-label Classification using Box Embeddings</div>
          <!-- Author -->
          <div class="author">
                  <em>Dhruvesh  Patel</em>, <a href="https://www.linkedin.com/in/sai-pavitra-dangati/" target="_blank" rel="noopener noreferrer">Pavitra Dangati</a>, <a href="https://leejayyoon.github.io/" target="_blank" rel="noopener noreferrer">Jay-Yoon Lee</a>, <a href="https://people.cs.umass.edu/~mboratko" target="_blank" rel="noopener noreferrer">Michael Boratko</a>, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations (To Appear)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multi-label classification is a challenging structured prediction task in which a set of output class labels are predicted for each input. Real-world datasets often have natural or latent taxonomic relationships between labels, making it desirable for models to employ label representations capable of capturing such taxonomies. Most existing multi-label classification methods do not do so, resulting in label predictions that are inconsistent with the taxonomic constraints, thus failing to accurately represent the fundamentals of problem setting. In this work, we introduce the multi-label box model (MBM), a multi-label classification method that combines the encoding power of neural networks with the inductive bias and probabilistic semantics of box embeddings (Vilnis, et al 2018).  Box embeddings can be understood as trainable Venn-diagrams based on hyper-rectangles.  Representing labels by boxes rather than vectors, MBM is able to capture taxonomic relations among labels.  Furthermore, since box embeddings allow these relations to be learned by stochastic gradient descent from data, and to be read as calibrated conditional probabilities, our model is endowed with a high degree of interpretability. This interpretability also facilitates the injection of partial information about label-label relationships into model training, to further improve its consistency. We provide theoretical grounding for our method and show experimentally the model’s ability to learn the true latent taxonomic structure from data. Through extensive empirical evaluations on both small and large-scale multi-label classification datasets, we show that BBM can significantly improve taxonomic consistency while preserving or surpassing the state-of-the-art predictive performance.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">patel2022modeling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modeling Label Space Interactions in Multi-label Classification using Box Embeddings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, Dhruvesh and Dangati, Pavitra and Lee, Jay-Yoon and Boratko, Michael and McCallum, Andrew}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations (To Appear)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=tyTH9kOxcvh}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICLR}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div>

        <!-- Entry bib key -->
        <div id="lee2022structured" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Structured Energy Network as a dynamic loss function. A case study with multi-label Classification</div>
          <!-- Author -->
          <div class="author">
<a href="https://leejayyoon.github.io/" target="_blank" rel="noopener noreferrer">Jay-Yoon Lee</a>, 
                  <em>Dhruvesh  Patel</em>, Purujit Goyal, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In (Under Review)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Belanger et. al. (2016) and Gygli et al. (2017) have shown that an energy network can capture arbitrary dependencies amongst the output variables in structured prediction; however, their reliance on gradient based inference (GBI) makes the inference slow and unstable. To take advantage of the expressivity of energy networks without incurring the high inference cost, in this work, we propose using Structured Energy As Loss (SEAL). This is a novel learning framework that uses energy network as a trainable loss function (loss-net) to train a separate neural network (task-net), which is then used to perform the inference through a forward pass. We establish SEAL as a general framework wherein various learning strategies like margin-based, regression, and noise-contrastive, could be employed to learn the parameters of loss-net. Through extensive evaluation on ten multi-label classification datasets, we demonstrate that SEAL as a general framework provides various useful design choices, is faster at inference than GBI, and leads to significant performance gains over the baselines.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="eventevent" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Event-Event Relation Extraction using Probabilistic Box Embedding</div>
          <!-- Author -->
          <div class="author">EunJeong Hwang, <a href="https://leejayyoon.github.io/" target="_blank" rel="noopener noreferrer">Jay-Yoon Lee</a>, Tianyi Yang, 
                  <em>Dhruvesh  Patel</em>, Dongxu Zhang, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (To Appear)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>To understand a story with multiple events, it is important to capture the proper relations across these events. However, existing event relation extraction (ERE) framework regards it as a multi-class classification task and do not guarantee any coherence between different relation types, such as anti-symmetry. If a phone line "died" after "storm", then it is obvious that the "storm" happened before the "died". Current framework of event relation extraction do not guarantee this coherence and thus enforces it via constraint loss function (Wang et al., 2020). In this work, we propose to modify the underlying ERE model to guarantee coherence by representing each event as a box representation (BERE) without applying explicit constraints. From our experiments, BERE also shows stronger conjunctive constraint satisfaction while performing on par or better in F1 compared to previous models with constraint injection.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div>

        <!-- Entry bib key -->
        <div id="dasgupta2021word2boy" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Word2Box: Learning Word Representation Using Box Embeddings</div>
          <!-- Author -->
          <div class="author">
<a href="https://ssdasgupta.github.io" target="_blank" rel="noopener noreferrer">Shib Sankar Dasgupta</a>, <a href="https://people.cs.umass.edu/~mboratko" target="_blank" rel="noopener noreferrer">Michael Boratko</a>, Shriya Atmakuri, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Li</a>, 
                  <em>Dhruvesh  Patel</em>, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ArXiv</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="chheda-etal-2021-box" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Box Embeddings: An open-source library for representation learning using geometric structures</div>
          <!-- Author -->
          <div class="author">*Tejas Cheda, *Purujit Goyal, *Trang Tran, 
                  <em>Dhruvesh  Patel</em>, <a href="https://people.cs.umass.edu/~mboratko" target="_blank" rel="noopener noreferrer">Michael Boratko</a>, <a href="https://ssdasgupta.github.io" target="_blank" rel="noopener noreferrer">Shib Sankar Dasgupta</a>, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em> Nov 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://github.com/iesl/box-embeddings" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A fundamental component to the success of modern representation learning is the ease of performing various vector operations. Recently, objects with more geometric structure (eg. distributions, complex or hyperbolic vectors, or regions such as cones, disks, or boxes) have been explored for their alternative inductive biases and additional representational capacity. In this work, we introduce Box Embeddings, a Python library that enables researchers to easily apply and extend probabilistic box embeddings. Fundamental geometric operations on boxes are implemented in a numerically stable way, as are modern approaches to training boxes which mitigate gradient sparsity. The library is fully open source, and compatible with both PyTorch and TensorFlow, which allows existing neural network layers to be replaced with or transformed into boxes easily. In this work, we present the implementation details of the fundamental components of the library, and the concepts required to use box representations alongside existing neural network architectures.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div>

        <!-- Entry bib key -->
        <div id="mishra-etal-2021-looking" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization</div>
          <!-- Author -->
          <div class="author">
<a href="https://www.linkedin.com/in/thisisanshuman/" target="_blank" rel="noopener noreferrer">Anshuman Mishra</a>, 
                  <em>Dhruvesh  Patel</em>, Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Lorraine Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" target="_blank" rel="noopener noreferrer">Pavan Kapanipathi</a>, and <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-krtalamad" target="_blank" rel="noopener noreferrer">Kartik Talamadupula</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em> Jun 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Natural Language Inference (NLI) has garnered significant attention in recent years; however, the promise of applying NLI breakthroughs to other downstream NLP tasks has remained unfulfilled. In this work, we use the multiple-choice reading comprehension (MCRC) and checking factual correctness of textual summarization (CFCS) tasks to investigate potential reasons for this. Our findings show that: (1) the relatively shorter length of premises in traditional NLI datasets is the primary challenge prohibiting usage in downstream applications (which do better with longer contexts); (2) this challenge can be addressed by automatically converting resource-rich reading comprehension datasets into longer-premise NLI datasets; and (3) models trained on the converted, longer-premise datasets outperform those trained using short-premise traditional NLI datasets on downstream tasks primarily due to the difference in premise lengths.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mishra-etal-2021-looking</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mishra, Anshuman and Patel, Dhruvesh and Vijayakumar, Aparna and Li, Xiang Lorraine and Kapanipathi, Pavan and Talamadupula, Kartik}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.naacl-main.104}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/nli-for-qa}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.naacl-main.104}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1322--1336}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NAACL}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="mishra2020looking" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Looking Beyond Sentence-Level Natural Language Inference for Downstream Tasks</div>
          <!-- Author -->
          <div class="author">*Anshuman Mishra, 
                  <em>*Dhruvesh  Patel</em>, *Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" target="_blank" rel="noopener noreferrer">Pavan Kapanipathi</a>, and <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-krtalamad" target="_blank" rel="noopener noreferrer">Kartik Talamadupula</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ArXiv</em> Dec 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In recent years, the Natural Language Inference (NLI) task has garnered significant attention, with new datasets and models achieving near human-level performance on it. However, the full promise of NLI – particularly that it learns knowledge that should be generalizable to other downstream NLP tasks – has not been realized. In this paper, we study this unfulfilled promise from the lens of two downstream tasks: question answering (QA), and text summarization. We conjecture that a key difference between the NLI datasets and these downstream tasks concerns the length of the premise; and that creating new long premise NLI datasets out of existing QA datasets is a promising avenue for training a truly generalizable NLI model. We validate our conjecture by showing competitive results on the task of QA and obtaining the best reported results on the task of Checking Factual Correctness of Summaries.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="mishra2020reading" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Reading Comprehension as Natural Language Inference: A Semantic Analysis</div>
          <!-- Author -->
          <div class="author">*Anshuman Mishra, 
                  <em>*Dhruvesh  Patel</em>, *Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" target="_blank" rel="noopener noreferrer">Pavan Kapanipathi</a>, and <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-krtalamad" target="_blank" rel="noopener noreferrer">Kartik Talamadupula</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In StarSem 2020 Workshop at COLING </em> Dec 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the recent past, Natural language Inference (NLI) has gained significant attention, particularly given its promise for downstream NLP tasks. However, its true impact is limited and has not been well studied. Therefore, in this paper, we explore the utility of NLI for one of the most prominent downstream tasks, viz. Question Answering (QA). We transform the one of the largest available MRC dataset (RACE) to an NLI form, and compare the performances of a state-of-the-art model (RoBERTa) on both these forms. We propose new characterizations of questions, and evaluate the performance of QA and NLI models on these categories. We highlight clear categories for which the model is able to perform better when the data is presented in a coherent entailment form, and a structured question-answer concatenation form, respectively.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="patel-etal-2020-weakly" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Weakly Supervised Medication Regimen Extraction from Medical Conversations</div>
          <!-- Author -->
          <div class="author">
                  <em>Dhruvesh  Patel</em>, <a href="https://skonam.github.io/" target="_blank" rel="noopener noreferrer">Sandeep Konam</a>, and <a href="http://saiprabhakar.github.io/" target="_blank" rel="noopener noreferrer">Sai Prabhakar</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 3rd Clinical Natural Language Processing Workshop</em> Nov 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Automated Medication Regimen (MR) extraction from medical conversations can not only improve recall and help patients follow through with their care plan, but also reduce the documentation burden for doctors. In this paper, we focus on extracting spans for frequency, route and change, corresponding to medications discussed in the conversation. We first describe a unique dataset of annotated doctor-patient conversations and then present a weakly supervised model architecture that can perform span extraction using noisy classification data. The model utilizes an attention bottleneck inside a classification model to perform the extraction. We experiment with several variants of attention scoring and projection functions and propose a novel transformer-based attention scoring function (TAScore). The proposed combination of TAScore and Fusedmax projection achieves a 10 point increase in Longest Common Substring F1 compared to the baseline of additive scoring plus softmax projection.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">patel-etal-2020-weakly</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised Medication Regimen Extraction from Medical Conversations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, Dhruvesh and Konam, Sandeep and Prabhakar, Sai}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 3rd Clinical Natural Language Processing Workshop}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2020.clinicalnlp-1.20}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2020.clinicalnlp-1.20}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{178--193}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ACL}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AKBC</abbr></div>

        <!-- Entry bib key -->
        <div id="dhruveshbox2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Representing Joint Hierarchies with Box Embeddings</div>
          <!-- Author -->
          <div class="author">
                  <em>*Dhruvesh  Patel</em>, *Shib Sankar Dasgupta, <a href="https://people.cs.umass.edu/~mboratko" target="_blank" rel="noopener noreferrer">Michael Boratko</a>, <a href="https://people.cs.umass.edu/~xiangl" target="_blank" rel="noopener noreferrer">Xiang Li</a>, <a href="https://people.cs.umass.edu/~luke" target="_blank" rel="noopener noreferrer">Luke Vilnis</a>, and <a href="https://people.cs.umass.edu/~mccallum" target="_blank" rel="noopener noreferrer">Andrew McCallum</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Automated Knowledge Base Construction (AKBC)</em> Nov 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://github.com/iesl/Boxes_for_Joint_hierarchy_AKBC_2020" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/assets/pdf/akbc2020-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning representations for hierarchical and multi-relational knowledge has emerged as an active area of research. Box Embeddings  [Vilnis et al., 2018, Li et al., 2019] represent concepts with hyperrectangles in n-dimensional space and are shown to be capable of modeling tree-like structures efficiently by training on a large subset of the transitive closure of the WordNet hypernym graph. In this work, we evaluate the capability of box embeddings to learn the transitive closure of a tree-like hierarchical relation graph with far fewer edges from the transitive closure. Box embeddings are not restricted to tree-like structures, however, and we demonstrate this by modeling the WordNet meronym graph, where nodes may have multiple parents. We further propose a method for modeling multiple relations jointly in a single embedding space using box embeddings. In all cases, our proposed method outperforms or is at par with all other embedding methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dhruveshbox2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Representing Joint Hierarchies with Box Embeddings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, *Dhruvesh and Dasgupta, *Shib Sankar and Boratko, Michael and Li, Xiang and Vilnis, Luke and McCallum, Andrew}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Automated Knowledge Base Construction (AKBC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=J246NSqR_l}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{akbc2020-slides.pdf}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/yqP8wjMocAs}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/iesl/Boxes_for_Joint_hierarchy_AKBC_2020}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AKBC}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="10.1007/978-3-319-44156-6_12" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Computing the Safe Working Zone of a 3-RRS Parallel Manipulator</div>
          <!-- Author -->
          <div class="author">
                  <em>Dhruvesh  Patel</em>, Rohit Kalla, Tetik Halil, Kiper Gökhan, and <a href="https://ed.iitm.ac.in/~sandipan" target="_blank" rel="noopener noreferrer">Sandipan Bandyopadhyay</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In New Trends in Mechanism and Machine Science</em> Nov 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Determination of the safe working zone (SWZ) of a parallel manipulator is a one-time computational task with several permanent benefits. As this subspace of the workspace of the manipulator is free of both the loss- and gain-type singularities, link interference, as well as physical joint limits, the manipulator can move freely in this space. Moreover, if the natural choice of a convex-shaped SWZ is adhered to, then point-to-point path planning inside the SWZ always has a trivial solution, namely, a segment joining the two points, which is guaranteed to be inside the workspace. In this paper, the SWZ of the 3-RRS existing in the İzmir Institute of Technology has been computed. Starting with the geometry of the manipulator, the loop-closure constraint equations have been derived. The singularity conditions are obtained based on the singularity of certain Jacobian matrices associated with the constraint functions. The interference between the links are detected by first encapsulating the links in rectangular parallelepipeds, which are then discretized into triangles, and subjected to collision tests between the relevant pairs of triangles. Using these theoretical developments, the SWZ is computed. The numerical results are depicted graphically.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Dhruvesh  Patel. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
Last updated: August 06, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-115661902-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-115661902-2');
  </script>
  </body>
</html>

