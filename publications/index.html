<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Dhruvesh Patel</title> <meta name="author" content="Dhruvesh Patel"> <meta name="description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar."> <meta name="keywords" content="personal-website"> <meta property="og:site_name" content="Dhruvesh Patel"> <meta property="og:type" content="website"> <meta property="og:title" content="Dhruvesh Patel | publications"> <meta property="og:url" content="https://dhruveshp.com/publications/"> <meta property="og:description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar."> <meta property="og:image" content="https://dhruveshp.com/assets/img/blog_logo.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="publications"> <meta name="twitter:description" content="Publications by categories in reversed chronological order. For the most up-to-date list check google scholar."> <meta name="twitter:image" content="https://dhruveshp.com/assets/img/blog_logo.png"> <meta name="twitter:site" content="@_dhruveshp"> <meta name="twitter:creator" content="@_dhruveshp"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Dhruvesh  Patel"
        },
        "url": "https://dhruveshp.com/publications/",
        "@type": "WebSite",
        "description": "Publications by categories in reversed chronological order. For the most up-to-date list check google scholar.",
        "headline": "publications",
        "sameAs": ["https://scholar.google.com/citations?user=6F2CvwoAAAAJ", "https://github.com/dhruvdcoder", "https://twitter.com/_dhruveshp"],
        "name": "Dhruvesh  Patel",
        "@context": "https://schema.org"
    }
    </script> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dhruveshp.com/publications/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Dhruvesh </span>Patel</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching and services</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/timeline/">timeline</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/repositories/">repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/teaching/">teaching</a> </div> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications by categories in reversed chronological order. For the most up-to-date list check google scholar.</p> </header> <article> <div class="publications"> <h2 class="year">2023</h2> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2"> <div class="abbr"><abbr class="badge" style="background-color:#00b300"><a href="https://www.thecvf.com/" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/vlamp_teaser-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/vlamp_teaser-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/vlamp_teaser-1400.webp"></source> <img src="/assets/img/publication_preview/vlamp_teaser.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="vlamp_teaser.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div id="patel2023pretrained" class="col-sm-8"> <div class="title">Pretrained Language Models as Visual Planners for Human Assistance</div> <div class="author"> <em>Dhruvesh Patel</em>, <a href="https://eghbalz.github.io/" rel="external nofollow noopener" target="_blank">Hamid Eghbalzadeh</a>, <a href="https://nitinkamra1992.github.io/" rel="external nofollow noopener" target="_blank">Nitin Kamra</a>, Michael Louis Iuzzolino, <a href="https://unnat.github.io/" rel="external nofollow noopener" target="_blank">Unnat Jain</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ruta Desai' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2304.09179" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/projects/vlamp_iccv_2023" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://github.com/facebookresearch/VLaMP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> <h2 class="year">2022</h2> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/acl/" rel="external nofollow noopener" target="_blank">ACL</a></abbr></div></div> <div id="dasgupta2021word2box" class="col-sm-8"> <div class="title">Word2Box: Capturing Set-Theoretic Semantics of Words using BoxEmbeddings</div> <div class="author"> <a href="https://ssdasgupta.github.io" rel="external nofollow noopener" target="_blank">Shib Sankar Dasgupta</a>, <a href="https://people.cs.umass.edu/~mboratko" rel="external nofollow noopener" target="_blank">Michael Boratko</a>, Siddhartha Mishra, Shriya Atmakuri, <em>Dhruvesh Patel</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Xiang Li, Andrew McCallum' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (To Appear)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, a prerequisite for nearly all modern machine-learning techniques. Often the objective is to capture distributional similarity via vector dot product, however this is just one relation between word meanings we may wish to capture. It is natural to consider words as (soft) equivalence classes based on similarity, it is natural to expect the ability to perform set-theoretic operations (intersection, union, difference) on these representations. This is particularly relevant for words which are homographs- for example, “tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should be similar to “dialect”. Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations. In this work, we provide a fuzzy-set interpretation of box embeddings, and train box embeddings with a CBOW objective where contexts are represented using intersection. We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#ff7f50"><a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a></abbr></div></div> <div id="patel2022modeling" class="col-sm-8"> <div class="title">Modeling Label Space Interactions in Multi-label Classification using Box Embeddings</div> <div class="author"> <em>Dhruvesh Patel</em>, <a href="https://www.linkedin.com/in/sai-pavitra-dangati/" rel="external nofollow noopener" target="_blank">Pavitra Dangati</a>, <a href="https://leejayyoon.github.io/" rel="external nofollow noopener" target="_blank">Jay-Yoon Lee</a>, <a href="https://people.cs.umass.edu/~mboratko" rel="external nofollow noopener" target="_blank">Michael Boratko</a>, and <a href="https://people.cs.umass.edu/~mccallum" rel="external nofollow noopener" target="_blank">Andrew McCallum</a> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Multi-label classification is a challenging structured prediction task in which a set of output class labels are predicted for each input. Real-world datasets often have natural or latent taxonomic relationships between labels, making it desirable for models to employ label representations capable of capturing such taxonomies. Most existing multi-label classification methods do not do so, resulting in label predictions that are inconsistent with the taxonomic constraints, thus failing to accurately represent the fundamentals of problem setting. In this work, we introduce the multi-label box model (MBM), a multi-label classification method that combines the encoding power of neural networks with the inductive bias and probabilistic semantics of box embeddings (Vilnis, et al 2018). Box embeddings can be understood as trainable Venn-diagrams based on hyper-rectangles. Representing labels by boxes rather than vectors, MBM is able to capture taxonomic relations among labels. Furthermore, since box embeddings allow these relations to be learned by stochastic gradient descent from data, and to be read as calibrated conditional probabilities, our model is endowed with a high degree of interpretability. This interpretability also facilitates the injection of partial information about label-label relationships into model training, to further improve its consistency. We provide theoretical grounding for our method and show experimentally the model’s ability to learn the true latent taxonomic structure from data. Through extensive empirical evaluations on both small and large-scale multi-label classification datasets, we show that BBM can significantly improve taxonomic consistency while preserving or surpassing the state-of-the-art predictive performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">patel2022modeling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modeling Label Space Interactions in Multi-label Classification using Box Embeddings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, Dhruvesh and Dangati, Pavitra and Lee, Jay-Yoon and Boratko, Michael and McCallum, Andrew}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=tyTH9kOxcvh}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#ff7f50"><a href="https://nips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a></abbr></div></div> <div id="lee2022structured" class="col-sm-8"> <div class="title">Structured Energy Network As a Loss</div> <div class="author"> <a href="https://leejayyoon.github.io/" rel="external nofollow noopener" target="_blank">Jay Yoon Lee</a>, <em>Dhruvesh Patel</em>, Purujit Goyal, Wenlong Zhao, Zhiyang Xu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Andrew McCallum' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Belanger &amp; McCallum (2016) and Gygli et al. (2017) have shown that an energy network can capture arbitrary dependencies amongst the output variables in structured prediction; however, their reliance on gradient-based inference (GBI) makes the inference slow and unstable. In this work, we propose Structured Energy As Loss (SEAL) to take advantage of the expressivity of energy networks without incurring the high inference cost. This is a novel learning framework that uses an energy network as a trainable loss function (loss-net) to train a separate neural network (task-net), which is then used to perform the inference through a forward pass. We establish SEAL as a general framework wherein various learning strategies like margin-based, regression, and noise-contrastive, could be employed to learn the parameters of loss-net. Through extensive evaluation on multi-label classification, semantic role labeling, and image segmentation, we demonstrate that SEAL provides various useful design choices, is faster at inference than GBI, and leads to significant performance gains over the baselines.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/acl/" rel="external nofollow noopener" target="_blank">ACL</a></abbr></div></div> <div id="eventevent" class="col-sm-8"> <div class="title">Event-Event Relation Extraction using Probabilistic Box Embedding</div> <div class="author"> EunJeong Hwang, <a href="https://leejayyoon.github.io/" rel="external nofollow noopener" target="_blank">Jay-Yoon Lee</a>, Tianyi Yang, <em>Dhruvesh Patel</em>, Dongxu Zhang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Andrew McCallum' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (To Appear)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>To understand a story with multiple events, it is important to capture the proper relations across these events. However, existing event relation extraction (ERE) framework regards it as a multi-class classification task and do not guarantee any coherence between different relation types, such as anti-symmetry. If a phone line "died" after "storm", then it is obvious that the "storm" happened before the "died". Current framework of event relation extraction do not guarantee this coherence and thus enforces it via constraint loss function (Wang et al., 2020). In this work, we propose to modify the underlying ERE model to guarantee coherence by representing each event as a box representation (BERE) without applying explicit constraints. From our experiments, BERE also shows stronger conjunctive constraint satisfaction while performing on par or better in F1 compared to previous models with constraint injection.</p> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge">Preprint</abbr></div></div> <div id="dasgupta2021word2boy" class="col-sm-8"> <div class="title">Word2Box: Learning Word Representation Using Box Embeddings</div> <div class="author"> <a href="https://ssdasgupta.github.io" rel="external nofollow noopener" target="_blank">Shib Sankar Dasgupta</a>, <a href="https://people.cs.umass.edu/~mboratko" rel="external nofollow noopener" target="_blank">Michael Boratko</a>, Shriya Atmakuri, <a href="https://people.cs.umass.edu/~xiangl" rel="external nofollow noopener" target="_blank">Xiang Li</a>, <em>Dhruvesh Patel</em>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Andrew McCallum' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In ArXiv</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2106.14361"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/emnlp/" rel="external nofollow noopener" target="_blank">EMNLP</a></abbr></div></div> <div id="chheda-etal-2021-box" class="col-sm-8"> <div class="title">Box Embeddings: An open-source library for representation learning using geometric structures</div> <div class="author"> *Tejas Cheda, *Purujit Goyal, *Trang Tran, <em>Dhruvesh Patel</em>, <a href="https://people.cs.umass.edu/~mboratko" rel="external nofollow noopener" target="_blank">Michael Boratko</a>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Shib Sankar Dasgupta, Andrew McCallum' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, Nov 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/iesl/box-embeddings" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2021.emnlp-demo.24"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2021.emnlp-demo.24" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>A fundamental component to the success of modern representation learning is the ease of performing various vector operations. Recently, objects with more geometric structure (eg. distributions, complex or hyperbolic vectors, or regions such as cones, disks, or boxes) have been explored for their alternative inductive biases and additional representational capacity. In this work, we introduce Box Embeddings, a Python library that enables researchers to easily apply and extend probabilistic box embeddings. Fundamental geometric operations on boxes are implemented in a numerically stable way, as are modern approaches to training boxes which mitigate gradient sparsity. The library is fully open source, and compatible with both PyTorch and TensorFlow, which allows existing neural network layers to be replaced with or transformed into boxes easily. In this work, we present the implementation details of the fundamental components of the library, and the concepts required to use box representations alongside existing neural network architectures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/naacl/" rel="external nofollow noopener" target="_blank">NAACL</a></abbr></div></div> <div id="mishra-etal-2021-looking" class="col-sm-8"> <div class="title">Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization</div> <div class="author"> <a href="https://www.linkedin.com/in/thisisanshuman/" rel="external nofollow noopener" target="_blank">Anshuman Mishra</a>, <em>Dhruvesh Patel</em>, Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" rel="external nofollow noopener" target="_blank">Xiang Lorraine Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" rel="external nofollow noopener" target="_blank">Pavan Kapanipathi</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Kartik Talamadupula' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2021.naacl-main.104"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2021.naacl-main.104" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Natural Language Inference (NLI) has garnered significant attention in recent years; however, the promise of applying NLI breakthroughs to other downstream NLP tasks has remained unfulfilled. In this work, we use the multiple-choice reading comprehension (MCRC) and checking factual correctness of textual summarization (CFCS) tasks to investigate potential reasons for this. Our findings show that: (1) the relatively shorter length of premises in traditional NLI datasets is the primary challenge prohibiting usage in downstream applications (which do better with longer contexts); (2) this challenge can be addressed by automatically converting resource-rich reading comprehension datasets into longer-premise NLI datasets; and (3) models trained on the converted, longer-premise datasets outperform those trained using short-premise traditional NLI datasets on downstream tasks primarily due to the difference in premise lengths.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mishra-etal-2021-looking</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mishra, Anshuman and Patel, Dhruvesh and Vijayakumar, Aparna and Li, Xiang Lorraine and Kapanipathi, Pavan and Talamadupula, Kartik}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.naacl-main.104}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.naacl-main.104}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1322--1336}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"></div> <div id="mishra2020looking" class="col-sm-8"> <div class="title">Looking Beyond Sentence-Level Natural Language Inference for Downstream Tasks</div> <div class="author"> *Anshuman Mishra, <em>*Dhruvesh Patel</em>, *Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" rel="external nofollow noopener" target="_blank">Xiang Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" rel="external nofollow noopener" target="_blank">Pavan Kapanipathi</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Kartik Talamadupula' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In ArXiv</em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2009.09099"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In recent years, the Natural Language Inference (NLI) task has garnered significant attention, with new datasets and models achieving near human-level performance on it. However, the full promise of NLI – particularly that it learns knowledge that should be generalizable to other downstream NLP tasks – has not been realized. In this paper, we study this unfulfilled promise from the lens of two downstream tasks: question answering (QA), and text summarization. We conjecture that a key difference between the NLI datasets and these downstream tasks concerns the length of the premise; and that creating new long premise NLI datasets out of existing QA datasets is a promising avenue for training a truly generalizable NLI model. We validate our conjecture by showing competitive results on the task of QA and obtaining the best reported results on the task of Checking Factual Correctness of Summaries.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/coling/" rel="external nofollow noopener" target="_blank">COLING</a></abbr></div></div> <div id="mishra2020reading" class="col-sm-8"> <div class="title">Reading Comprehension as Natural Language Inference: A Semantic Analysis</div> <div class="author"> *Anshuman Mishra, <em>*Dhruvesh Patel</em>, *Aparna Vijayakumar, <a href="https://people.cs.umass.edu/~xiangl" rel="external nofollow noopener" target="_blank">Xiang Li</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-kapanipa" rel="external nofollow noopener" target="_blank">Pavan Kapanipathi</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Kartik Talamadupula' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In StarSem 2020 Workshop at COLING </em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/nli-for-qa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2010.01713"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In the recent past, Natural language Inference (NLI) has gained significant attention, particularly given its promise for downstream NLP tasks. However, its true impact is limited and has not been well studied. Therefore, in this paper, we explore the utility of NLI for one of the most prominent downstream tasks, viz. Question Answering (QA). We transform the one of the largest available MRC dataset (RACE) to an NLI form, and compare the performances of a state-of-the-art model (RoBERTa) on both these forms. We propose new characterizations of questions, and evaluate the performance of QA and NLI models on these categories. We highlight clear categories for which the model is able to perform better when the data is presented in a coherent entailment form, and a structured question-answer concatenation form, respectively.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#0000ff"><a href="https://aclanthology.org/venues/acl/" rel="external nofollow noopener" target="_blank">ACL</a></abbr></div></div> <div id="patel-etal-2020-weakly" class="col-sm-8"> <div class="title">Weakly Supervised Medication Regimen Extraction from Medical Conversations</div> <div class="author"> <em>Dhruvesh Patel</em>, <a href="https://skonam.github.io/" rel="external nofollow noopener" target="_blank">Sandeep Konam</a>, and <a href="http://saiprabhakar.github.io/" rel="external nofollow noopener" target="_blank">Sai Prabhakar</a> </div> <div class="periodical"> <em>In Proceedings of the 3rd Clinical Natural Language Processing Workshop</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2020.clinicalnlp-1.20"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2020.clinicalnlp-1.20" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Automated Medication Regimen (MR) extraction from medical conversations can not only improve recall and help patients follow through with their care plan, but also reduce the documentation burden for doctors. In this paper, we focus on extracting spans for frequency, route and change, corresponding to medications discussed in the conversation. We first describe a unique dataset of annotated doctor-patient conversations and then present a weakly supervised model architecture that can perform span extraction using noisy classification data. The model utilizes an attention bottleneck inside a classification model to perform the extraction. We experiment with several variants of attention scoring and projection functions and propose a novel transformer-based attention scoring function (TAScore). The proposed combination of TAScore and Fusedmax projection achieves a 10 point increase in Longest Common Substring F1 compared to the baseline of additive scoring plus softmax projection.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">patel-etal-2020-weakly</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised Medication Regimen Extraction from Medical Conversations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, Dhruvesh and Konam, Sandeep and Prabhakar, Sai}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 3rd Clinical Natural Language Processing Workshop}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2020.clinicalnlp-1.20}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2020.clinicalnlp-1.20}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{178--193}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><div class="abbr"><abbr class="badge" style="background-color:#b28080"><a href="https://akbc.ws/" rel="external nofollow noopener" target="_blank">AKBC</a></abbr></div></div> <div id="dhruveshbox2020" class="col-sm-8"> <div class="title">Representing Joint Hierarchies with Box Embeddings</div> <div class="author"> <em>*Dhruvesh Patel</em>, *Shib Sankar Dasgupta, <a href="https://people.cs.umass.edu/~mboratko" rel="external nofollow noopener" target="_blank">Michael Boratko</a>, <a href="https://people.cs.umass.edu/~xiangl" rel="external nofollow noopener" target="_blank">Xiang Li</a>, <a href="https://people.cs.umass.edu/~luke" rel="external nofollow noopener" target="_blank">Luke Vilnis</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Andrew McCallum' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Automated Knowledge Base Construction (AKBC)</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/iesl/Boxes_for_Joint_hierarchy_AKBC_2020" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/akbc2020-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Learning representations for hierarchical and multi-relational knowledge has emerged as an active area of research. Box Embeddings [Vilnis et al., 2018, Li et al., 2019] represent concepts with hyperrectangles in n-dimensional space and are shown to be capable of modeling tree-like structures efficiently by training on a large subset of the transitive closure of the WordNet hypernym graph. In this work, we evaluate the capability of box embeddings to learn the transitive closure of a tree-like hierarchical relation graph with far fewer edges from the transitive closure. Box embeddings are not restricted to tree-like structures, however, and we demonstrate this by modeling the WordNet meronym graph, where nodes may have multiple parents. We further propose a method for modeling multiple relations jointly in a single embedding space using box embeddings. In all cases, our proposed method outperforms or is at par with all other embedding methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dhruveshbox2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Representing Joint Hierarchies with Box Embeddings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Patel, *Dhruvesh and Dasgupta, *Shib Sankar and Boratko, Michael and Li, Xiang and Vilnis, Luke and McCallum, Andrew}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Automated Knowledge Base Construction (AKBC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=J246NSqR_l}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/yqP8wjMocAs}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2"></div> <div id="10.1007/978-3-319-44156-6_12" class="col-sm-8"> <div class="title">Computing the Safe Working Zone of a 3-RRS Parallel Manipulator</div> <div class="author"> <em>Dhruvesh Patel</em>, Rohit Kalla, Tetik Halil, Kiper Gökhan, and <a href="https://ed.iitm.ac.in/~sandipan" rel="external nofollow noopener" target="_blank">Sandipan Bandyopadhyay</a> </div> <div class="periodical"> <em>In New Trends in Mechanism and Machine Science</em>, Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-isbn="978-3-319-44156-6"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Determination of the safe working zone (SWZ) of a parallel manipulator is a one-time computational task with several permanent benefits. As this subspace of the workspace of the manipulator is free of both the loss- and gain-type singularities, link interference, as well as physical joint limits, the manipulator can move freely in this space. Moreover, if the natural choice of a convex-shaped SWZ is adhered to, then point-to-point path planning inside the SWZ always has a trivial solution, namely, a segment joining the two points, which is guaranteed to be inside the workspace. In this paper, the SWZ of the 3-RRS existing in the İzmir Institute of Technology has been computed. Starting with the geometry of the manipulator, the loop-closure constraint equations have been derived. The singularity conditions are obtained based on the singularity of certain Jacobian matrices associated with the constraint functions. The interference between the links are detected by first encapsulating the links in rectangular parallelepipeds, which are then discretized into triangles, and subjected to collision tests between the relevant pairs of triangles. Using these theoretical developments, the SWZ is computed. The numerical results are depicted graphically.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Dhruvesh Patel. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: September 03, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-115661902-2"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-115661902-2");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>