---
layout: about
title: about
permalink: /
#description: <a href="#current_affiliations">Current </a> and <a href="#past_affiliations">past</a> affiliations.


profile:
  align: right
  image: dp.jpg
  address: >
     <p>dhruveshpate@umass.edu</p>
  image_circular: false # crops the image to make it circular


news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
collaborators: true
timeline: true
social: true  # includes social icons at the bottom of the page
---


ðŸŒŸ **I'm looking for internship opportunities for Spring and Summer 2025. Here is my [CV](https://drive.google.com/file/d/1Z8u4_wnQiLDkyiV361f-kGfxHpb6NQCE/view).** ðŸŒŸ 
<br><br>
I am currently a fourth-year Computer Science PhD student at [UMass Amherst](https://www.umass.edu/) working with [Prof. Andrew McCallum](https://people.cs.umass.edu/~mccallum) alongside some amazing colleagues at the [Information Extraction and Synthesis Laboratory](https://iesl.cs.umass.edu/).
I completed my undergraduate at [IIT Madras](https://www.iitm.ac.in), where I worked on Robotics research, mentored by [Prof. Bandyopadhyay](https://ed.iitm.ac.in/~sandipan).

Outside of my academic pursuits, I've been fortunate to have worked with some amazing collaborators from the industry. I have worked as a research scientist inter at [Meta Reality Labs](https://ai.meta.com/) and [Abridge AI](https://www.abridge.com/machine-learning).
Before beginning my master's program at UMass, I worked for two years as a software engineer at [MathWorks](https://www.mathworks.com/).
I also dedicated a year to collaborating with [Prof. Partha Talukdar](http://talukdar.net) on solving various NLP problems in the industry.


## research

As someone with a deep fascination for the abstract concepts of mathematics and a strong drive to create tangible impact in the world, I strive for a balanced approach in my research. My focus revolves around bridging the gap between abstract ideas and tangible applications of machine learning. This dual approach has led me to explore the applications of machine learning in robotics, NLP, and knowledge graphs, while also nurturing my passion for foundational aspects of machine learning such as representation learning.
While most representation learning methods only focus on metric learning, my work on box embeddings aims to show that representation learning can also capture various other kinds of structures like algebraic and relational structure, thereby allowing models to perform compositional reasoning.
I believe that learning objectives based on max-likelihood alone are restrictive and will not get us very far. As a result, I have explored energy models, where the objective is to use energy model as a learned loss function to train a feedforward prediction network. 
My current research focuses on non-autoregessive training and inference for sequence models for text generation,
I'm particularly interested in training generative models using masked/permutation language modeling and discrete diffusion like training objectives.
I am also interested in analyzing the limits of compositional generalization in latent space achievable through in-context learning with sequence models.


