---
layout: about
title: about
permalink: /
#description: <a href="#current_affiliations">Current </a> and <a href="#past_affiliations">past</a> affiliations.


profile:
  align: right
  image: dp.jpg
  address: >
     <p>dhruveshpate@umass.edu</p>
  #  <p>555 your office number</p>
  #  <p>123 your address street</p>
  #  <p>Your City, State 12345</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

## bio

I am a second year Computer Science PhD student at UMass Amherst working with [Prof. Andrew McCallum](https://people.cs.umass.edu/~mccallum).
During my time as a master's student at UMass, I worked as a research intern at [Information Extraction and Synthesis Lab (IESL)](http://www.iesl.cs.umass.edu/people) and [Abridge AI](https://www.abridge.com/machine-learning). Prior to starting my master's program I had spent a year working with [Prof. Partha Talukdar](http://talukdar.net) on various NLP problems.
I obtained by undergrad from [IIT Madras](https://www.iitm.ac.in), where, under the guidance of [Prof. Bandyopadhyay](https://ed.iitm.ac.in/~sandipan), my research primarily focused on problems in Robotics. I have also worked for 2 years as a software engineer at [MathWorks](https://www.mathworks.com/).

## research

Coming with an eclectic background–a mix of robotics, software engineering, natural language processing, and mathematics–I like to think about foundational aspects of machine learning, with major focus on representation learning.
While most representation learning methods only focus on metric learning, my work on box embeddings aims to show that representation learning can also capture various other kinds of structures like algebraic and relational structure, thereby allowing models to perform compositional reasoning.
I have also worked with energy models, where the goal is to utilize energy as a *learned* loss function to train feedforward prediction network. My most recent empirical explorations have been on NLP and structured prediction tasks.
Going forward, I am most interested analysing deep representation learning in rich non-Euclidean spaces through the lens of the burgeoning theory of deep learning.
